<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>Unsupervised Thoughts</title>
		<description>A blog on machine learning</description>
		<link>https://vivien000.github.io/blog</link>
		<atom:link href="https://vivien000.github.io/blog/rss-feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Fast, High-Fidelity LLM Decoding with Regex Constraints</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;p&gt;&lt;strong&gt;Constraining the text generated by an LLM&lt;/strong&gt; is essential for developing robust LLM applications. For example, a developer may require LLM responses to adhere to a specific JSON or YAML schema so that they are comprehensive and reliably parseable.&lt;/p&gt;

</description>
				
				<pubDate>Thu, 22 Feb 2024 00:00:00 +0100</pubDate>
				<link>https://vivien000.github.io/journal/llm-decoding-with-regex-constraints.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/llm-decoding-with-regex-constraints.html</guid>
			</item>
		
			<item>
				<title>An Optimal Lossy Variant of Speculative Decoding</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;p&gt;&lt;strong&gt;Speculative decoding&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#leviathan2023fast&quot;&gt;(Leviathan et al., 2023; Chen et al., 2023)&lt;/a&gt; is an elegant decoding strategy for autoregressive language models. It &lt;strong&gt;accelerates text generation while preserving the target distribution&lt;/strong&gt;. In this blog post, I introduce &lt;strong&gt;mentored decoding&lt;/strong&gt;, a novel, provably optimal, lossy variant of speculative decoding. It &lt;strong&gt;further increases the decoding speed at the cost of a bounded deviation from the target distribution&lt;/strong&gt;.&lt;/p&gt;

</description>
				
				<pubDate>Mon, 18 Sep 2023 00:00:00 +0200</pubDate>
				<link>https://vivien000.github.io/journal/a-provably-optimal-lossy-variant-of-speculative-decoding.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/a-provably-optimal-lossy-variant-of-speculative-decoding.html</guid>
			</item>
		
			<item>
				<title>Better Steering LLM Agents with LMQL</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;p&gt;One of the most fascinating aspects of autoregressive &lt;strong&gt;large language models&lt;/strong&gt; (LLMs) like GPT-3 is their ability to &lt;strong&gt;act through external tools&lt;/strong&gt;. In this post, I’ll illustrate how &lt;strong&gt;LMQL&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#beurer2022prompting&quot;&gt;(Beurer-Kellner et al., 2022)&lt;/a&gt;, a new &lt;em&gt;programming language for language model interaction&lt;/em&gt;, helps better steer such LLM agents. I’ll take &lt;strong&gt;ReAct&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#yao2022react&quot;&gt;(Yao et al., 2022)&lt;/a&gt; as an example and show how to enforce &lt;strong&gt;constraints on the task-solving trajectory, the choice of tools and the tools’ inputs&lt;/strong&gt;.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 28 Apr 2023 00:00:00 +0200</pubDate>
				<link>https://vivien000.github.io/journal/better-steering-LLM-agents-with-LMQL.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/better-steering-LLM-agents-with-LMQL.html</guid>
			</item>
		
			<item>
				<title>Adding Text (Really) inside Pictures and Videos</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;p&gt;In the image above and the video below, the left character partially hides the text. In this post, I show how to automatically create such effect with a pretrained deep learning model and traditional computer vision techniques.&lt;/p&gt;

</description>
				
				<pubDate>Wed, 08 Jun 2022 00:00:00 +0200</pubDate>
				<link>https://vivien000.github.io/journal/adding-text-inside-pictures-and-videos.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/adding-text-inside-pictures-and-videos.html</guid>
			</item>
		
			<item>
				<title>Simulating Depth Perception with Face Tracking</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;p&gt;&lt;strong&gt;Motion parallax&lt;/strong&gt; is created by the apparent relative motion of objects when an observer moves. It’s one of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Depth_perception#Monocular_cues&quot;&gt;monocular cues&lt;/a&gt; that enable depth perception. I created a &lt;a href=&quot;https://vivien000.github.io/trompeloeil/&quot;&gt;demo&lt;/a&gt; to simulate this phenomenon thanks to &lt;a href=&quot;https://www.tensorflow.org/js/models&quot;&gt;TensorFlow.js&lt;/a&gt; and &lt;a href=&quot;https://threejs.org/&quot;&gt;three.js&lt;/a&gt;.&lt;/p&gt;

</description>
				
				<pubDate>Tue, 04 May 2021 00:00:00 +0200</pubDate>
				<link>https://vivien000.github.io/journal/motion-parallax-with-face-tracking.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/motion-parallax-with-face-tracking.html</guid>
			</item>
		
			<item>
				<title>What Are the Ethical Risks of Your AI Project?</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;div class=&quot;caption_cover_image&quot;&gt;How to prevent AI systems from causing unintended harms?&lt;/div&gt;

</description>
				
				<pubDate>Fri, 20 Nov 2020 00:00:00 +0100</pubDate>
				<link>https://vivien000.github.io/journal/ethical-risks-ai-project.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/ethical-risks-ai-project.html</guid>
			</item>
		
			<item>
				<title>Learning through Auxiliary Tasks</title>
				
					<dc:creator>Vivien</dc:creator>
				
				
					<description>&lt;div class=&quot;caption_cover_image&quot;&gt;Play, a seemingly futile activity, is ubiquitous in human cultures and very widespread in the animal kingdom, which suggests it serves an important purpose&lt;/div&gt;

</description>
				
				<pubDate>Sun, 17 Feb 2019 00:00:00 +0100</pubDate>
				<link>https://vivien000.github.io/journal/learning-though-auxiliary_tasks.html</link>
				<guid isPermaLink="true">https://vivien000.github.io/journal/learning-though-auxiliary_tasks.html</guid>
			</item>
		
	</channel>
</rss>
