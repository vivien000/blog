<!doctype html>
<html>

<head>

  <title>
    
      Learning through Auxiliary Tasks | Unsupervised Thoughts
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="https://vivien000.github.io/blog/assets/css/main.css">
  <link rel="stylesheet" href="https://vivien000.github.io/blog/assets/css/syntax.css">
  <!-- Use Atom -->
  <!-- <link type="application/atom+xml" rel="alternate" href="https://vivien000.github.io/blog/rss-feed.xml" title="Unsupervised Thoughts" /> -->
  <!-- Use RSS-2.0 -->
  <link href="https://vivien000.github.io/blog/rss-feed.xml" type="application/rss+xml" rel="alternate" title="Unsupervised Thoughts | A blog on machine learning"/>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFFMKRY3GE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFFMKRY3GE');
</script>


  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Learning through Auxiliary Tasks | Unsupervised Thoughts</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Learning through Auxiliary Tasks" />
<meta name="author" content="Vivien" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Play, a seemingly futile activity, is ubiquitous in human cultures and very widespread in the animal kingdom, which suggests it serves an important purpose" />
<meta property="og:description" content="Play, a seemingly futile activity, is ubiquitous in human cultures and very widespread in the animal kingdom, which suggests it serves an important purpose" />
<link rel="canonical" href="https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html" />
<meta property="og:url" content="https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html" />
<meta property="og:site_name" content="Unsupervised Thoughts" />
<meta property="og:image" content="https://vivien000.github.io/blog/vase.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-17T00:00:00+01:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://vivien000.github.io/blog/vase.jpg" />
<meta property="twitter:title" content="Learning through Auxiliary Tasks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Vivien"},"dateModified":"2019-02-17T00:00:00+01:00","datePublished":"2019-02-17T00:00:00+01:00","description":"Play, a seemingly futile activity, is ubiquitous in human cultures and very widespread in the animal kingdom, which suggests it serves an important purpose","headline":"Learning through Auxiliary Tasks","image":"https://vivien000.github.io/blog/vase.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html"},"url":"https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html"}</script>
<!-- End Jekyll SEO tag -->


</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="https://vivien000.github.io/blog/">Unsupervised Thoughts</a>
    <small class="masthead-subtitle">A blog on machine learning</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="https://vivien000.github.io/blog/menu/about.html">About</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/vivien000" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/vivien000000" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://vivien000.github.io/blog/rss-feed.xml" target="_blank"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:vivien@melix.net" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  Learning through Auxiliary Tasks
</h1>


  <img src="https://vivien000.github.io/blog/assets/img/vase.jpg">


<div class="caption_cover_image">Play, a seemingly futile activity, is ubiquitous in human cultures and very widespread in the animal kingdom, which suggests it serves an important purpose</div>

<p><strong>Update</strong>: this blog post was expanded into a <a href="https://github.com/vivien000/auxiliary-learning2/blob/master/auxiliary_tasks.pdf">paper</a> with more explanations and additional experiments.</p>

<p>In this post, I’d like to illustrate how <strong>auxiliary tasks</strong> can be beneficial for <strong>machine learning</strong>. I’ll first define this notion, provide examples and show how these tasks are usually incorporated in the mathematical formulation of <strong>deep learning</strong> problems. I’ll then propose an alternative approach and present first experimental results for this approach.</p>

<ul id="markdown-toc">
  <li><a href="#auxiliary-tasks-in-machine-learning" id="markdown-toc-auxiliary-tasks-in-machine-learning">Auxiliary Tasks in Machine Learning</a></li>
  <li><a href="#standard-approach-for-deep-auxiliary-learning" id="markdown-toc-standard-approach-for-deep-auxiliary-learning">Standard Approach for Deep Auxiliary Learning</a></li>
  <li><a href="#an-alternative-approach" id="markdown-toc-an-alternative-approach">An Alternative Approach</a></li>
  <li><a href="#comparison-to-uweighted-and-weighted-cosine" id="markdown-toc-comparison-to-uweighted-and-weighted-cosine">Comparison to Uweighted and Weighted Cosine</a></li>
  <li><a href="#experiments" id="markdown-toc-experiments">Experiments</a>    <ul>
      <li><a href="#toy-experiments" id="markdown-toc-toy-experiments">Toy Experiments</a></li>
      <li><a href="#experiments-on-a-real-dataset" id="markdown-toc-experiments-on-a-real-dataset">Experiments on a Real Dataset</a></li>
      <li><a href="#experiments-on-a-synthetic-dataset" id="markdown-toc-experiments-on-a-synthetic-dataset">Experiments on a Synthetic Dataset</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h1 id="auxiliary-tasks-in-machine-learning">Auxiliary Tasks in Machine Learning</h1>

<p>In machine learning, <strong>auxiliary tasks</strong> are tasks we try to accomplish with the sole objective of better performing one or several <strong>primary tasks</strong>. This situation, referred to here as <strong>auxiliary learning</strong>, contrasts with <strong>multitask learning</strong><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, for which we are genuinely interested in accomplishing well all tasks, and <strong>single task learning</strong>, for which only one task is considered.</p>

<table>
  <tr>
    <th class="no_border"></th>
    <th>Tasks performed during training</th>
    <th>Tasks considered when assessing performance</th>
  </tr>
  <tr>
    <td><b>Single task learning</b></td>
    <td colspan="2">One task</td>
  </tr>
  <tr>
    <td><b>Multitask learning</b></td>
    <td colspan="2">Several tasks</td>
  </tr>
  <tr>
    <td><b>Auxiliary learning</b></td>
    <td>One or several primary tasks, one or several auxiliary tasks</td>
    <td>Primary tasks</td>
  </tr>
</table>

<div class="caption">Table 1. Auxiliary learning compared to single task learning and multitask learning</div>

<p>Let’s look at a striking example <a class="citation" href="#caruana1996using">(Caruana et al., 1996)</a> based on the Medis Pneumonia Database. This database contains 14,199 cases of patients diagnosed with pneumonia and hospitalized. It includes:</p>
<ul>
  <li>30 basic measurements (e.g. pulse);</li>
  <li>35 lab results (e.g. blood counts);</li>
  <li>the indication whether each patient survived or died.</li>
</ul>

<p>Rich Caruana and his colleagues’ primary task was to identify patients that were more likely to survive and should then not be hospitalized. In this context, the lab results, available only after hospitalization, couldn’t be used as inputs. However, it was still possible to take advantage of them. Rich Caruana and his colleagues tried, as an auxiliary task, to predict the lab results based on the basic measurements. They thus reduced the error rate for their primary task by 5-10%.</p>

<p>Auxiliary learning has often been successfully applied in other settings, such as in the examples below:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Domain</strong></td>
      <td><strong>Primary task</strong></td>
      <td><strong>Auxiliary tasks</strong></td>
      <td><strong>Source</strong></td>
    </tr>
    <tr>
      <td><strong>Deep learning</strong></td>
      <td>Training a deep neural network</td>
      <td>Reconstructing corrupted versions of the neural network’s inputs and the activations of its hidden layers to learn useful features</td>
      <td><a class="citation" href="#vincent2008extracting">(Vincent et al., 2008)</a></td>
    </tr>
    <tr>
      <td><strong>Computer vision</strong></td>
      <td>Identifying facial landmarks on face pictures</td>
      <td>Estimating head pose and predicting facial attributes (“wearing glasses”, “smiling” and “gender”)</td>
      <td><a class="citation" href="#Zhang14faciallandmark">(Zhang et al., 2014)</a></td>
    </tr>
    <tr>
      <td><strong>Computer vision</strong></td>
      <td>Detecting objects in indoor scenes</td>
      <td>Predicting scene labels and evaluating depth and surface orientation at pixel level</td>
      <td><a class="citation" href="#mordan2018revisiting">(Mordan et al., 2018)</a></td>
    </tr>
    <tr>
      <td><strong>Sequence modelling</strong></td>
      <td>Training a recurrent neural network on very long sequences</td>
      <td>Reconstructing or predicting short segments of the sequences</td>
      <td><a class="citation" href="#trinh2018learning">(Trinh et al., 2018)</a></td>
    </tr>
    <tr>
      <td><strong>Natural language processing</strong></td>
      <td>Performing a natural language processing task</td>
      <td>Predicting words based on their neighborhood to learn efficient word representations</td>
      <td><a class="citation" href="#mikolov2013distributed">(Mikolov et al., 2013)</a></td>
    </tr>
    <tr>
      <td><strong>Reinforcement learning</strong></td>
      <td>Playing a video game</td>
      <td>Modifying the image perceived by the agent and predicting short-term rewards</td>
      <td><a class="citation" href="#jaderberg2016reinforcement">(Jaderberg et al., 2016)</a></td>
    </tr>
    <tr>
      <td><strong>Reinforcement learning</strong></td>
      <td>Playing a video game</td>
      <td>Predicting the future state based on the current state and the current action</td>
      <td><a class="citation" href="#burda2018large">(Burda et al., 2018)</a></td>
    </tr>
  </tbody>
</table>

<div class="caption">Table 2. Auxiliary learning has been successfully used in a variety of settings</div>

<h1 id="standard-approach-for-deep-auxiliary-learning">Standard Approach for Deep Auxiliary Learning</h1>

<p>For the sake of clarity, let’s consider only the case of a single primary task and a single auxiliary task (generalizing to an arbitrary number of primary and auxiliary tasks is straightforward). Let’s suppose further that these tasks correspond to the minimization of a <strong>primary loss</strong> \(\mathcal{L}_{\text{primary}}\) and an <strong>auxiliary loss</strong> \(\mathcal{L}_{\text{auxiliary}}\).</p>

<p>In the context of deep learning, the standard approach<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> is to use a single neural network for both tasks, with shared layers followed by task-specific layers, and to apply a gradient descent-based method to minimize the weighted sum of the two losses \(\mathcal{L} = \mathcal{L}_{\text{primary}} + \lambda \mathcal{L}_{\text{auxiliary}}\).</p>

<p>The corresponding gradient is \(\nabla\mathcal{L} = \nabla\mathcal{L}_{\text{primary}} + \lambda \nabla\mathcal{L}_{\text{auxiliary}}\).</p>

<p>The underlying intuition is that minimizing \(\mathcal{L}\) will lead to <strong>more meaningful representations in the shared layers</strong> and that these representations will be leveraged by the layers specific to the primary task.</p>

<p>In the standard multitask approach, \(\lambda\) is a constant value<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. Its purpose is to <strong>balance the primary task and the auxiliary task</strong>. \(\lambda = 0\) corresponds to single task learning whereas increasing \(\lambda\) gives more and more influence to the auxiliary task.</p>

<h1 id="an-alternative-approach">An Alternative Approach</h1>

<p>The approach described above has provided very good empirical results. However, an auxiliary task may be unhelpful or even harmful for the primary task. The latter case, which is called <strong>negative transfer</strong>, is a central challenge of auxiliary learning.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/negative_transfer.png" alt="Negative transfer" /></p>
<div class="caption">Figure 1. Left: a pathological example of negative transfer with an auxiliary task chosen so that \(\mathcal{L}_{\text{auxiliary}} = -\mathcal{L}_{\text{primary}}\). In this case, \(\nabla\mathcal{L} = 0\) (assuming \(\lambda = 1\)) and the network's parameters are never updated during gradient descent. Right: a less extreme situation in which \(\nabla\mathcal{L}_{\text{auxiliary}}\) still cancels a significant part of \(\nabla\mathcal{L}_{\text{primary}}\)</div>

<p>Moreover, using a weighted average of \(\mathcal{L}_{\text{primary}}\) and \(\mathcal{L}_{\text{auxiliary}}\) suggests we’d be willing to tolerate a higher value of \(\mathcal{L}_{\text{primary}}\) if it helped sufficiently decrease \(\mathcal{L}_{\text{auxiliary}}\). On the contrary, reducing the auxiliary loss is only looked for to the extent this contributes to reducing the primary loss.</p>

<p>To <strong>mitigate negative transfer and better reflect the fundamental asymmetry between the primary loss and the auxiliary loss</strong>, I suggest substituting \(\nabla\mathcal{L}\) with:</p>

\[G = \nabla\mathcal{L}_{\text{primary}} + \lambda G_{\text{auxiliary}}\]

<p>where \(G_{\text{auxiliary}}\) is:</p>
<ul>
  <li>as close as possible to \(\nabla\mathcal{L}_{\text{auxiliary}}\), to preserve the insights brought by the auxiliary task;</li>
  <li>closer to \(\nabla\mathcal{L}_{\text{primary}}\) than \(-\nabla\mathcal{L}_{\text{primary}}\), to avoid following a direction detrimental to the primary task.</li>
</ul>

<p>Otherwise said, <strong>\(G_{\text{auxiliary}}\) is the projection of \(\nabla\mathcal{L}_{\text{auxiliary}}\) on the half-space of vectors whose cosine similarity with \(\nabla\mathcal{L}_{\text{primary}}\) is positive</strong>. If a critical point of \(\mathcal{L}_{\text{primary}}\) hasn’t been reached yet (i.e. if \(\nabla\mathcal{L}_{\text{primary}} \neq \mathbf{0}\)), this ensures that \(\mathcal{L}_{\text{primary}}\) will decrease if the learning rate if small enough.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/projection.png" alt="Projection of the auxiliary loss gradient" /></p>
<div class="caption">Figure 2. If \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) form an obtuse angle, the component of \(\nabla\mathcal{L}_{\text{auxiliary}}\) parallel to \(\nabla\mathcal{L}_{\text{primary}}\) is cancelled to avoid increasing \(\mathcal{L}_{\text{primary}}\). If not, \(\nabla\mathcal{L}_{\text{auxiliary}}\) is kept as it is</div>

<h1 id="comparison-to-uweighted-and-weighted-cosine">Comparison to Uweighted and Weighted Cosine</h1>

<p>This approach, referred below as <strong>projection</strong>, is analogous to two methods, <strong>unweighted cosine</strong> and <strong>weighted cosine</strong>, recently proposed for the same purpose <a class="citation" href="#du2018adapting">(Du et al., 2018)</a>. Yunshu Du,  Wojciech Czarnecki and their colleagues also suggest to adjust \(\nabla\mathcal{L}_{\text{auxiliary}}\):</p>

<table>
  <tbody>
    <tr>
      <td><strong>Method</strong></td>
      <td><strong>Adjusted auxiliary loss gradient</strong> \(G_{\text{auxiliary}}\)</td>
    </tr>
    <tr>
      <td><strong>Unweighted cosine</strong></td>
      <td>\(\left\{\begin{array}{lll}\nabla\mathcal{L}_{\text{auxiliary}}&amp;\mbox{if }\cos(\nabla\mathcal{L}_{\text{primary}},\nabla\mathcal{L}_{\text{auxiliary}}) \geq 0 \\ 0&amp;\mbox{if }\cos(\nabla\mathcal{L}_{\text{primary}},\nabla\mathcal{L}_{\text{auxiliary}}) &lt; 0\end{array}\right.\)</td>
    </tr>
    <tr>
      <td><strong>Weighted cosine</strong></td>
      <td>\(\max(0, \cos(\nabla\mathcal{L}_{\text{primary}},\nabla\mathcal{L}_{\text{auxiliary}})).\nabla\mathcal{L}_{\text{auxiliary}}\)</td>
    </tr>
    <tr>
      <td><strong>Projection</strong></td>
      <td>\(\nabla\mathcal{L}_{\text{auxiliary}} - \min(0, \nabla\mathcal{L}_{\text{auxiliary}}.\frac{\nabla\mathcal{L}_{\text{primary}}}{||\nabla\mathcal{L}_{\text{primary}}||}).\frac{\nabla\mathcal{L}_{\text{primary}}}{||\nabla\mathcal{L}_{\text{primary}}||}\)</td>
    </tr>
  </tbody>
</table>

<div class="caption">Table 3. Unweighted cosine and weighted cosine compared to the method proposed here</div>

<p>If \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) form an acute angle, both <em>projection</em> and <em>unweighted cosine</em> leave \(\nabla\mathcal{L}_{\text{auxiliary}}\) unchanged whereas <em>weighted cosine</em> reduces its norm with the cosine similarity of these vectors. In particular, <em>weighted cosine</em> strongly shrinks \(\nabla\mathcal{L}_{\text{auxiliary}}\) when it becomes almost orthogonal to \(\nabla\mathcal{L}_{\text{primary}}\).</p>

<p>If \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) form an obtuse angle, both <em>unweighted cosine</em> and <em>weighted cosine</em> just ignore \(\nabla\mathcal{L}_{\text{auxiliary}}\). In contrast, <em>projection</em> only negates the component of \(\nabla\mathcal{L}_{\text{auxiliary}}\) which is collinear to \(\nabla\mathcal{L}_{\text{primary}}\).</p>

<p><img src="https://vivien000.github.io/blog/assets/img/cosine.png" alt="Unweighted and weighted cosine" /></p>
<div class="caption">Figure 3. \(\nabla\mathcal{L}_{\text{auxiliary}}\) transformed into \(G_{\text{auxiliary}}\) by unweighted cosine (red) and weighted cosine (purple)</div>

<p>Even if <em>projection</em> and <em>unweighted/weighted cosine</em> are similar, their motivations are different:</p>

<ul>
  <li>
    <p><a class="citation" href="#du2018adapting">(Du et al., 2018)</a> explicitly tries to favor auxiliary tasks similar to the primary task. For example, <em>weighted cosine</em> completely ignores the auxiliary task when \(\nabla\mathcal{L}_{\text{auxiliary}}\) and \(\nabla\mathcal{L}_{\text{primary}}\) are orthogonal.</p>
  </li>
  <li>
    <p>In my intuition, an auxiliary task’s purpose is to bring a new perspective. It should nudge us towards interesting regions of the parameter space we wouldn’t have explored with only the primary task in focus. Therefore we can try to negate the component of \(\nabla\mathcal{L}_{\text{auxiliary}}\) which seems clearly harmful to our objective but we shouldn’t necessarily discard auxiliary tasks dissimilar to the primary task<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">4</a></sup>.</p>
  </li>
</ul>

<h1 id="experiments">Experiments</h1>

<p>Let’s now look at some experiments. They were performed with Tensorflow and you can find the corresponding notebooks and additional results on <a href="https://github.com/vivien000/auxiliary-learning">GitHub</a>.</p>

<h2 id="toy-experiments">Toy Experiments</h2>

<p>We start with a minimalistic example to illustrate how substituting \(\nabla\mathcal{L}_{\text{auxiliary}}\) with \(G_{\text{auxiliary}}\) gives priority to the primary task while still allowing progress on the auxiliary task.</p>

<p>In the <strong>euclidean plane</strong> \(\mathbb{R^2}\), we try to find a point \((x, y)\) that, <strong>above all, minimizes the square distance to the unit circle</strong> and, only if it doesn’t increase this distance, also <strong>minimizes the square distance to point (2, 0)</strong>.</p>

<p>Otherwise said, \(\mathcal{L}_{\text{primary}} = (\sqrt{x^2+y^2}-1)^2\) and \(\mathcal{L}_{\text{auxiliary}} = (x-2)^2+y^2\).</p>

<p>This is a slight departure from the principle of auxiliary learning described above. Here we want to accomplish both the primary task and the auxiliary task even if the primary task is the absolute priority (performing the primary task alone would be too easy).</p>

<p><strong>The solution of this problem is of course</strong> \((1, 0)\) and we try to reach it by <strong>using a gradient descent-based algorithm</strong> starting from point \((0, 2)\) with \(\lambda = 0.1\).</p>

<p><img src="https://vivien000.github.io/blog/assets/img/trajectories_adam.gif" alt="Adam trajectories" /></p>
<div class="caption">Figure 4. Trajectories with Adam</div>

<p>We can see the corresponding trajectories with the <strong>Adam algorithm</strong> (learning rate: 0.01, \(\beta_1=0.9, \beta_2=0.999\)) on Figure 4 and observe that:</p>

<ul>
  <li>
    <p>With <em>multitask</em>, the point converges to a location close to but different from (1, 0) because of the distraction the auxiliary task creates.</p>
  </li>
  <li>
    <p>With <em>projection</em>, the point follows as expected the same trajectory as with <em>multitask</em> before reaching the disk of radius 1 and center (1, 0), i.e. as long as \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) form an acute angle. Afterwards, the point slightly deviates from the <em>multitask</em> trajectory to reach (1, 0).</p>
  </li>
  <li>
    <p>The trajectory for <em>unweighted cosine</em> is also the same before reaching the disk of radius 1 and center (1, 0). Afterwards, the point abruptly changes course in the direction of the unit disk as the auxiliary task is ignored. When the point arrives at the unit disk, it starts oscillating around its edge. It’s then intermittently influenced by the auxiliary task and follows the unit circle until reaching (1, 0).</p>
  </li>
  <li>
    <p>With <em>weighted cosine</em>, the point follows a more direct trajectory towards the unit circle. It then arrives close to the intersection between the unit circle and the circle of radius 1 and center (1, 0), i.e. a location where \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) are orthogonal. It stagnates there for a while because the auxiliary task is mostly ignored then converges to (1, 0) by following the unit circle.</p>
  </li>
</ul>

<p>With this example, <strong><em>projection</em>, <em>unweighted cosine</em> and <em>weighted cosine</em> allow to find the correct solution but the convergence is notably quicker with <em>projection</em></strong> (this is also the case for <a href="https://vivien000.github.io/blog/assets/img/trajectories_adam2.gif">other</a> <a href="https://vivien000.github.io/blog/assets/img/trajectories_adam3.gif">starting</a> <a href="https://vivien000.github.io/blog/assets/img/trajectories_adam4.gif">points</a>).</p>

<p><img src="https://vivien000.github.io/blog/assets/img/trajectories_vanilla_gd.gif" alt="Vanilla Gradient Descent trajectories" /></p>
<div class="caption">Figure 5. Trajectories with vanilla gradient descent</div>

<p>Figure 5 shows the trajectories with the <strong>vanilla gradient descent algorithm</strong> (learning rate: 0.01) and tells a different story. <strong>With <em>unweighted cosine</em> and <em>weighted cosine</em>, the point now stops on the unit circle far from (1, 0)</strong>. This is because, in the absence of momentum, it eventually stays on the side of the unit circle where \(\nabla\mathcal{L}_{\text{primary}}\) and \(\nabla\mathcal{L}_{\text{auxiliary}}\) form an obtuse angle. The auxiliary task is then never taken into consideration anymore. A similar behavior can be seen with <a href="https://vivien000.github.io/blog/assets/img/trajectories_vanilla_gd2.gif">other</a> <a href="https://vivien000.github.io/blog/assets/img/trajectories_vanilla_gd3.gif">starting</a> <a href="https://vivien000.github.io/blog/assets/img/trajectories_vanilla_gd4.gif">points</a>.</p>

<p>In summary, the proposed method works as intended with these toy examples: it helps accomplish both the primary task and the auxiliary task while giving precedence to the former.</p>

<h2 id="experiments-on-a-real-dataset">Experiments on a Real Dataset</h2>

<p>The following experiments are based on the <strong><em>CelebA (or large-scale CelebFaces attributes) dataset</em></strong> <a class="citation" href="#liu2015faceattributes">(Liu et al., 2015)</a> and inspired by <a class="citation" href="#Zhang14faciallandmark">(Zhang et al., 2014)</a>. The CelebA dataset contains many face images annotated with 40 binary attributes such as <em>Attractive</em>, <em>Young</em>, <em>Eyeglasses</em> or <em>Black Hair</em>, and the locations of 5 facial landmarks : <em>left eye</em>, <em>right eye</em>, <em>left mouth corner</em>, <em>right mouth corner</em> and <em>nose</em>.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/faces.png" alt="Example of a CelebA image" /></p>
<div class="caption">Figure 6. Examples of CelebA images and their 40 x 40 downsampled gray-scale versions with green dots on the 5 facial landmarks</div>

<p>The <strong>primary task</strong> for these experiments is to <strong>determine whether a face is attractive</strong> (or at least attractive in the annotators’ eyes) and the <strong>auxiliary task</strong> is to <strong>locate the facial landmarks</strong>. The corresponding losses are the cross entropy error function and the average quadratic error.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/neural_network1.png" alt="Neural network for the real dataset" /></p>
<div class="caption">Figure 7. Convolutional network with 4 convolutional layers interleaved with 3 max-pooling layers, a shared dense layer, and a final dense layer specific to each task</div>

<p>The pictures were downsampled to \(40\times40\) and converted to gray-scale to make the tasks more challenging and reduce computation time. 10000 of them were included in the training set, the validation set and the test set. I used the neural network depicted on Figure 7 as in <a class="citation" href="#Zhang14faciallandmark">(Zhang et al., 2014)</a> and trained it with the Adam algorithm and early stopping.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/real_dataset_chart1.png" alt="AUC for single task, multitask and projection" /></p>
<div class="caption">Figure 8. Testing AUC for <i>single task</i>, <i>multitask</i> and <i>projection</i> and 5 values of \(\lambda\) (10 runs for each combination). The bands around the lines on this chart and the next ones correspond to the 95% confidence interval</div>

<p>Figure 8 shows the testing AUC for the primary task with <em>single task</em>, <em>multitask</em> and <em>projection</em> and various values of \(\lambda\):</p>

<ul>
  <li>Unsurprisingly enough, the <em>multitask</em> and <em>projection</em> curves get close to the <em>single task</em> curve as the influence of the auxiliary task becomes marginal for low values of \(\lambda\);</li>
  <li><strong>The classification performance is better for <em>multitask</em> and <em>projection</em> than for <em>single task</em></strong> for intermediate values of \(\lambda\). Moreover, <strong>the median testing AUC at the best \(\lambda\) value for <em>projection</em> is slightly but statistically significantly higher than the one for <em>multitask</em></strong> (\(p = 0.005\) with the Wilcoxon signed-rank test);</li>
  <li>The classification performance deteriorates as the influence of the auxiliary task becomes excessive with high values of \(\lambda\), especially for <em>multitask</em> which performs worse than <em>single task</em> for \(\lambda = 30000\).</li>
</ul>

<p><img src="https://vivien000.github.io/blog/assets/img/real_dataset_chart2.png" alt="AUC for all modes" /></p>
<div class="caption">Figure 9. Testing AUC for <i>single task</i>, <i>multitask</i>, <i>projection</i>, <i>unweighted cosine</i> and <i>weighted cosine</i> and 5 values of \(\lambda\) (10 runs for each combination)</div>

<p>We can compare these results with those for <em>unweighted cosine</em> and <em>weighted cosine</em> on Figure 9. The <em>unweighted cosine</em> curve and the <em>weighted cosine</em> curve are very close to respectively the <em>projection</em> curve and the <em>single task</em> curve for \(\lambda \leq 10000\). However, their testing AUC drops for \(\lambda = 30000\). We can note that the <em>weighted cosine</em> curve falls between the <em>single task</em> curve and the <em>unweighted cosine</em> curve, which comes as no surprise.</p>

<h2 id="experiments-on-a-synthetic-dataset">Experiments on a Synthetic Dataset</h2>

<p>The last series of experiments follows <a class="citation" href="#DBLP:conf/icml/ChenBLR18">(Chen et al., 2018)</a> and uses a <strong>synthetic dataset to control the adequacy of the auxiliary task</strong>.</p>

<p>Let:</p>
<ul>
  <li>\(f(B, \mathbf{x}) = \tanh(B\mathbf{x})\) where \(\tanh(\cdot)\) acts element-wise, \(\mathbf{x}\) is a real-valued vector of length \(250\) and \(B\) is a \(100 \times 250\) real-valued matrix.</li>
  <li>\(B_\mathbb{primary}\), \(B\) and \(\epsilon\) be constant \(100 \times 250\) real-valued matrices whose elements are drawn IID respectively from \(\mathcal{N}(0, 10)\), \(\mathcal{N}(0, 10)\) and \(\mathcal{N}(0, 3.5)\).</li>
</ul>

<p>The <strong>primary task</strong> and the <strong>auxiliary task</strong> consist in approximating respectively \(f(B_\mathbb{primary},\cdot)\) and \(f(B_\mathbb{auxiliary},\cdot)\) with the quadratic loss function where \(B_\mathbb{auxiliary}\) can be equal to:</p>
<ul>
  <li>\(B_\mathbb{primary}\) (<strong>both tasks are the same</strong>)</li>
  <li>\(B_\mathbb{primary} + \epsilon\) (<strong>both tasks are similar</strong>)</li>
  <li>\(B\) (<strong>both tasks are unrelated</strong>)</li>
</ul>

<p>For the input data (i.e. \(\mathbf{x}\)), the training set, the validation set and the test set include respectively 1000, 1000 and 10000 vectors whose elements are generated IID from \(\mathcal{N}(0, 1)\). Moreover and as opposed to the previous series of experiments, <strong>the training sets are distinct for the primary task and the auxiliary task</strong>. If these sets were the same, the auxiliary task wouldn’t add any value when \(B_\mathbb{primary} = B_\mathbb{auxiliary}\).</p>

<p><img src="https://vivien000.github.io/blog/assets/img/neural_network2.png" alt="Neural network for the synthetic dataset" /></p>
<div class="caption">Figure 10. Multilayer perceptron with 4 shared layers and an output layer specific to each task, all of them being of size 100</div>

<p>As <a class="citation" href="#DBLP:conf/icml/ChenBLR18">(Chen et al., 2018)</a>, I used the vanilla neural network depicted on Figure 10, which I trained with the Adam algorithm and early stopping.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/synthetic_dataset_chart1.png" alt="AUC for single task, multitask and projection" /></p>
<div class="caption">Figure 11. Testing loss for <i>single task</i>, <i>multitask</i> and <i>projection</i> for 5 values of \(\lambda\) (20 runs for each combination)</div>

<p>Figure 11 shows the results for <em>single task</em>, <em>multitask</em> and <em>projection</em> for various values of \(\lambda\). <strong>The outcomes for <em>multitask</em> and <em>projection</em> are almost identical and fully consistent with the 3 situations for the auxiliary task</strong> (same task, similar task and unrelated task):</p>
<ul>
  <li>when the auxiliary task is the same as the primary task, it significantly contributes to the performance of the primary task for all 5 values of \(\lambda\).</li>
  <li>when the auxiliary task is similar to but different from the primary task, it helps for \(\lambda \leq 1\) but becomes neutral or harmful for \(\lambda \geq 3\).</li>
  <li>when the auxiliary task is unrelated to the primary task, it’s detrimental to the performance of the primary task for \(\lambda \geq 0.3\).</li>
</ul>

<p>In contrast to the previous series of experiments, <strong>Figure 11 suggests <em>projection</em> has no added value compared to <em>multitask</em></strong>. This difference may result from the fact that <strong>the primary task and the auxiliary task don’t share here the same input data</strong>. As a consequence, at each optimization step, \(\nabla\mathcal{L}_{\text{primary}}\) is less related to \(\nabla\mathcal{L}_{\text{auxiliary}}\) and might then be too noisy to help properly adjust it. Therefore I tried substituting \(\nabla\mathcal{L}_{\text{primary}}\) with an <strong>exponential moving average of \(\nabla\mathcal{L}_{\text{primary}}\)</strong> for adjusting \(\nabla\mathcal{L}_{\text{auxiliary}}\). With a smoothing constant \(0 &lt; \alpha \leq 1\), \(G_{\text{auxiliary}}\) is then given at each optimization step \(t\) by:</p>

\[G_{\text{auxiliary}}(t) = \nabla\mathcal{L}_{\text{auxiliary}}(t) - \min(0, \nabla\mathcal{L}_{\text{auxiliary}}(t).\frac{M(t)}{||M(t)||})\frac{M(t)}{||M(t)||}\]

<p>with \(M(0) = \nabla\mathcal{L}_{\text{primary}}(0)\) and \(M(t) = \alpha\nabla\mathcal{L}_{\text{primary}}(t) + (1-\alpha)M(t-1)\) for \(t &gt; 0\).</p>

<p><img src="https://vivien000.github.io/blog/assets/img/synthetic_dataset_chart2.png" alt="AUC for all modes" /></p>
<div class="caption">Figure 12. Testing loss for <i>single task</i>, <i>multitask</i> and <i>projection</i> for 5 values of \(\lambda\) and 3 values of \(\alpha\) (20 runs for each combination)</div>

<p>Figure 12 shows the same results as Figure 11 for 3 values of \(\alpha\). With \(\alpha = 0.1\) and even more <strong>with \(\alpha = 0.01\), <em>projection</em> yields clearly better results compared to <em>multitask</em> for all 3 situations</strong><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">5</a></sup>. Figure 13 zooms in on the case \(\alpha = 0.01\), for which <em>unweighted cosine</em> and <em>weighted cosine</em> provide better results than <em>multitask</em> and <em>projection</em> only when the primary task and the auxiliary task are unrelated.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/synthetic_dataset_chart3.png" alt="AUC for various scales" /></p>
<div class="caption">Figure 13. Testing loss for <i>single task</i>, <i>multitask</i>, <i>projection</i>, <i>unweighted cosine</i> and <i>weighted cosine</i> for 5 values of \(\lambda\) and \(\alpha = 0.01\) (20 runs for each combination)</div>

<h1 id="conclusion">Conclusion</h1>

<p><strong>Leveraging auxiliary tasks is an elegant way to improve learning</strong>, especially in the case of supervised learning with too few labelled examples or reinforcement learning with sparse rewards. However, auxiliary tasks may sometimes hurt the performance on the primary task.</p>

<p>In this blog post, I proposed a <strong>simple and intuitive method to mitigate such risk of negative transfer</strong>. I tested it in a few basic scenarios, in which it brought <strong>moderate but statistically significant gains over the standard multitask approach</strong>. This is a promising start but more diverse and elaborate experimental settings would be necessary to draw general conclusions on this method’s relevance or compare it with its alternatives.</p>

<p><em>Many thanks to the authors of the inspiring articles listed below and the developers of the great tools used for this post: <a href="https://www.tensorflow.org/">Tensorflow</a>, the <a href="https://www.scipy.org/">SciPy</a> ecosystem, <a href="https://www.scipy.org/">Seaborn</a>, <a href="https://colab.research.google.com">Google Colab</a>, <a href="https://github.com/HarisIqbal88/PlotNeuralNet">PlotNeuralNet</a> and <a href="https://jekyllrb.com/">Jekyll</a>. Many thanks as well to Sebastian Ruder for his valuable feedback.</em></p>

<h1 id="references">References</h1>

<ol class="bibliography"><li><span id="caruana1996using">Caruana, R., Baluja, S., &amp; Mitchell, T. (1996). Using the future to "sort out" the present: Rankprop and multitask learning for medical risk evaluation. <i>Advances in Neural Information Processing Systems</i>, 959–965.</span></li>
<li><span id="vincent2008extracting">Vincent, P., Larochelle, H., Bengio, Y., &amp; Manzagol, P.-A. (2008). Extracting and composing robust features with denoising autoencoders. <i>Proceedings of the 25th International Conference on Machine Learning</i>, 1096–1103.</span></li>
<li><span id="Zhang14faciallandmark">Zhang, Z., Luo, P., Loy, C. C., &amp; Tang, X. (2014). Facial landmark detection by deep multi-task learning. <i>In ECCV. 94–108</i>.</span></li>
<li><span id="mordan2018revisiting">Mordan, T., Thome, N., Henaff, G., &amp; Cord, M. (2018). Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection. <i>Advances in Neural Information Processing Systems</i>, 1317–1329.</span></li>
<li><span id="trinh2018learning">Trinh, T. H., Dai, A. M., Luong, T., &amp; Le, Q. V. (2018). Learning longer-term dependencies in rnns with auxiliary losses. <i>ArXiv Preprint ArXiv:1803.00144</i>.</span></li>
<li><span id="mikolov2013distributed">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., &amp; Dean, J. (2013). Distributed representations of words and phrases and their compositionality. <i>Advances in Neural Information Processing Systems</i>, 3111–3119.</span></li>
<li><span id="jaderberg2016reinforcement">Jaderberg, M., Mnih, V., Czarnecki, W. M., Schaul, T., Leibo, J. Z., Silver, D., &amp; Kavukcuoglu, K. (2016). Reinforcement learning with unsupervised auxiliary tasks. <i>ArXiv Preprint ArXiv:1611.05397</i>.</span></li>
<li><span id="burda2018large">Burda, Y., Edwards, H., Pathak, D., Storkey, A., Darrell, T., &amp; Efros, A. A. (2018). Large-scale study of curiosity-driven learning. <i>ArXiv Preprint ArXiv:1808.04355</i>.</span></li>
<li><span id="du2018adapting">Du, Y., Czarnecki, W. M., Jayakumar, S. M., Pascanu, R., &amp; Lakshminarayanan, B. (2018). Adapting auxiliary losses using gradient similarity. <i>ArXiv Preprint ArXiv:1812.02224</i>.</span></li>
<li><span id="liu2015faceattributes">Liu, Z., Luo, P., Wang, X., &amp; Tang, X. (2015, December). Deep Learning Face Attributes in the Wild. <i>Proceedings of International Conference on Computer Vision (ICCV)</i>.</span></li>
<li><span id="DBLP:conf/icml/ChenBLR18">Chen, Z., Badrinarayanan, V., Lee, C.-Y., &amp; Rabinovich, A. (2018). GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep
               Multitask Networks. <i>Proceedings of the 35th International Conference on Machine Learning,
               ICML 2018, Stockholmsmässan, Stockholm, Sweden, July
               10-15, 2018</i>, 793–802. http://proceedings.mlr.press/v80/chen18a.html</span></li></ol>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The terminology for auxiliary learning is somewhat unclear in the academic litterature. Auxiliary learning may or may not be included in multitask learning depending on the papers. In this post, I restrict multitask learning to the situations where all tasks are taken into account to assess the model’s performance. Consequently multitask learning is here disjoint from auxiliary learning. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Sebastian Ruder presents this approach as well as other approaches in his very good <a href="http://ruder.io/multi-task/index.html">overview of multitask learning</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>\(\lambda\) varies in certain methods not presented here. <strong>Transfer learning</strong> can be seen as a specific case for which \(\lambda = \infty\) in a first stage and \(\lambda = 0\) in a second stage. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>As an extreme example, an auxiliary task identical to the primary task and yielding the same gradients would be unhelpful provided that the learning rate is appropriately tuned. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>It may be surprising that <em>multitask</em> isn’t the best training mode when the primary task and the auxiliary task are the same. In fact, the situation isn’t fully symmetrical because the primary task helps train the corresponding task-specific last layer which isn’t affected by the auxiliary task. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>


<span class="post-date">
  Written on
  
  February
  17th,
  2019
  by
  
    Vivien
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Learning through Auxiliary Tasks&amp;url=https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=https://vivien000.github.io/blog/journal/learning-though-auxiliary_tasks.html&amp;title=Learning through Auxiliary Tasks" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
  </div>
</div>



  <section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = "unsupervisedthoughts";
    var disqus_identifier = "/journal/learning-though-auxiliary_tasks.html";
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/vivien000" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/vivien000000" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://vivien000.github.io/blog/rss-feed.xml" target="_blank"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:vivien@melix.net" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="https://vivien000.github.io/blog/menu/about.html">Unsupervised Thoughts | A blog on machine learning by Vivien</a></div>
</footer>


  </div>

</body>
</html>
