<!doctype html>
<html>

<head>

  <title>
    
      Adding Text (Really) inside Pictures and Videos | Unsupervised Thoughts
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="https://vivien000.github.io/blog/assets/css/main.css">
  <link rel="stylesheet" href="https://vivien000.github.io/blog/assets/css/syntax.css">
  <!-- Use Atom -->
  <!-- <link type="application/atom+xml" rel="alternate" href="https://vivien000.github.io/blog/rss-feed.xml" title="Unsupervised Thoughts" /> -->
  <!-- Use RSS-2.0 -->
  <link href="https://vivien000.github.io/blog/rss-feed.xml" type="application/rss+xml" rel="alternate" title="Unsupervised Thoughts | A blog on machine learning"/>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Google Analytics -->
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SFFMKRY3GE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SFFMKRY3GE');
</script>


  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Adding Text (Really) inside Pictures and Videos | Unsupervised Thoughts</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Adding Text (Really) inside Pictures and Videos" />
<meta name="author" content="Vivien" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In the image above and the video below, the left character partially hides the text. In this post, I show how to automatically create such effect with a pretrained deep learning model and traditional computer vision techniques." />
<meta property="og:description" content="In the image above and the video below, the left character partially hides the text. In this post, I show how to automatically create such effect with a pretrained deep learning model and traditional computer vision techniques." />
<link rel="canonical" href="https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html" />
<meta property="og:url" content="https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html" />
<meta property="og:site_name" content="Unsupervised Thoughts" />
<meta property="og:image" content="https://vivien000.github.io/blog/weirwood.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-08T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://vivien000.github.io/blog/weirwood.png" />
<meta property="twitter:title" content="Adding Text (Really) inside Pictures and Videos" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html"},"url":"https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html","image":"https://vivien000.github.io/blog/weirwood.png","author":{"@type":"Person","name":"Vivien"},"headline":"Adding Text (Really) inside Pictures and Videos","dateModified":"2022-06-08T00:00:00+02:00","datePublished":"2022-06-08T00:00:00+02:00","description":"In the image above and the video below, the left character partially hides the text. In this post, I show how to automatically create such effect with a pretrained deep learning model and traditional computer vision techniques.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="https://vivien000.github.io/blog/">Unsupervised Thoughts</a>
    <small class="masthead-subtitle">A blog on machine learning</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="https://vivien000.github.io/blog/menu/about.html">About</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/vivien000" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/vivien000000" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://vivien000.github.io/blog/rss-feed.xml" target="_blank"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:vivien@melix.net" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  Adding Text (Really) inside Pictures and Videos
</h1>


  <img src="https://vivien000.github.io/blog/assets/img/weirwood.png">


<p>In the image above and the video below, the left character partially hides the text. In this post, I show how to automatically create such effect with a pretrained deep learning model and traditional computer vision techniques.</p>

<p>I focus here on the general approach and you can see the implementation details (and create your own videos!) with the attached <a href="https://colab.research.google.com/github/vivien000/depth-aware_captioning/blob/master/Depth_aware_Video_Captioning.ipynb">notebook</a>. You can also edit pictures through a user-friendly <a href="https://huggingface.co/spaces/vivien/depth-aware-caption">web app</a>.</p>

<ul id="markdown-toc">
  <li><a href="#adding-text-to-a-single-picture" id="markdown-toc-adding-text-to-a-single-picture">Adding Text to a Single Picture</a></li>
  <li><a href="#aligning-two-frames" id="markdown-toc-aligning-two-frames">Aligning two Frames</a></li>
  <li><a href="#adding-text-to-a-video" id="markdown-toc-adding-text-to-a-video">Adding Text to a Video</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<div class="iframe-container">
<iframe class="responsive-iframe" src="https://www.youtube-nocookie.com/embed/videoseries?list=PLlPB25tBWqtVhj4Ink8hl9Evc2dlIX4Jh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>

<h1 id="adding-text-to-a-single-picture">Adding Text to a Single Picture</h1>

<p>As illustrated in the following diagram, adding text to a single picture is straigthforward:</p>

<ol>
  <li>
    <p><strong>Depth estimation</strong>: we get a <strong>depth map</strong> of the picture with <a href="https://huggingface.co/Intel/dpt-large">MiDaS</a> <a class="citation" href="#Ranftl2020">(Ranftl et al., 2020)</a><a class="citation" href="#Ranftl2021">(Ranftl et al., 2021)</a>, a deep learning model trained specifically for this task.</p>
  </li>
  <li>
    <p><strong>Depth-aware image fusion</strong>: we prepare <strong>an image with the desired text</strong> over a transparent background and we specify a <strong>depth threshold</strong>. We then merge it with the initial image on the basis of the depth map: for each pixel, if its depth is below the threshold, we keep the color of the initial image and if not, we replace it with the color of the text image.</p>
  </li>
</ol>

<p><img src="https://vivien000.github.io/blog/assets/img/single_frame.png" alt="Approach for a single frame" /></p>

<h1 id="aligning-two-frames">Aligning two Frames</h1>

<p>With videos, the result is <strong>much more convincing if the added text seems static even though the camera moves</strong>. If we have already chosen the position of text for a reference frame and want to determine the position for another frame, <strong>we need to estimate the camera movements between the two frames</strong>. We’ll then be able to compensate them to create the illusion of a static text.</p>

<p>This is done in 3 steps:</p>

<ol>
  <li>
    <p><strong>Keypoints detection and description</strong>: we use ORB <a class="citation" href="#orb">(Rublee et al., 2011)</a> and BEBLID <a class="citation" href="#SUAREZ2020">(Suárez et al., 2020)</a> to detect <strong><em>keypoints</em></strong> in both frames and obtain their <strong><em>descriptions</em></strong>. <em>Keypoints</em> are pixels whose neighborhood is distinctive (e.g. a pixel located at a corner) and the descriptions are binary vector representations of these neighborhoods’ visual appearance. In the OpenCV implementation of ORB, it’s possible to detect keypoints only in a region of an image so we take advantage of the depth maps we already computed to look for keypoints only in the background. We can indeed assume that these keypoints would better reflect the camera movements.</p>
  </li>
  <li>
    <p><strong>Keypoints matching</strong>: for each keypoint of the reference frame, we search for keypoints with a similar description in the other frame and we do so naively by testing all potential pairs. This yields a <strong>list of matched keypoints</strong>.</p>
  </li>
  <li>
    <p><strong>Affine transformation estimation</strong>: we look for the <strong>affine function that best transforms the keypoints of the reference frame into the ones of the other frame</strong>. For this, we could use a simple linear regression. However, there can be false positives among the matched keypoints or the changes of these keypoints from one frame to another may not be caused only by the camera motion. This is why we use RANSAC <a class="citation" href="#RANSAC">(Fischler &amp; Bolles, 1981)</a>, an iterative curve fitting method robust to outliers.</p>
  </li>
</ol>

<p><img src="https://vivien000.github.io/blog/assets/img/two_frames.png" alt="Approach to align two frames" /></p>

<h1 id="adding-text-to-a-video">Adding Text to a Video</h1>

<p>We’re almost there! For each frame of a video, we now know how to determine the affine function best aligning this frame with a reference frame and we could use this affine function to transform the text image before merging it with the frame. However, the estimation errors of the affine function would then make the text appear jittery. This is why we use a <strong>nonparametric kernel regression to smoothen all parameters of the affine function over time</strong>.</p>

<p><img src="https://vivien000.github.io/blog/assets/img/smoothening.png" alt="Smoothening of the affine function parameters" /></p>
<div class="caption">Estimated (dashed blue line) and smoothened (full orange line) parameters of the affine function</div>

<h1 id="conclusion">Conclusion</h1>

<p>I find it satisfying to see how traditional computer vision methods and a deep learning model can be jointly used to produce convincing results. It’s also pleasantly straightforward to combine these techniques with powerful Python libraries like <a href="https://opencv.org">OpenCV</a> and <a href="https://huggingface.co/docs/transformers/index">transformers</a>. I hope you’ve enjoyed this blog post. Let me know if you use the notebook to create cool videos!</p>

<p><em>This project was inspired by the official <a href="https://youtu.be/eTa1jHk1Lxc">video</a> of Jenny of Oldstones by Florence + the Machine and built with <a href="https://opencv.org">OpenCV</a>, <a href="https://huggingface.co/docs/transformers/index">transformers</a>, the <a href="https://huggingface.co/Intel/dpt-large">MiDaS model</a> and <a href="https://colab.research.google.com">Google Colab</a>.</em></p>

<h1 id="references">References</h1>

<ol class="bibliography"><li><span id="Ranftl2020">Ranftl, R., Lasinger, K., Hafner, D., Schindler, K., &amp; Koltun, V. (2020). Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>.</span></li>
<li><span id="Ranftl2021">Ranftl, R., Bochkovskiy, A., &amp; Koltun, V. (2021). Vision Transformers for Dense Prediction. <i>ArXiv Preprint</i>.</span></li>
<li><span id="orb">Rublee, E., Rabaud, V., Konolige, K., &amp; Bradski, G. (2011). ORB: An efficient alternative to SIFT or SURF. <i>2011 International Conference on Computer Vision</i>, 2564–2571. https://doi.org/10.1109/ICCV.2011.6126544</span></li>
<li><span id="SUAREZ2020">Suárez, I., Sfeir, G., Buenaposada, J. M., &amp; Baumela, L. (2020). BEBLID: Boosted Efficient Binary Local Image Descriptor. <i>Pattern Recognition Letters</i>. https://doi.org/https://doi.org/10.1016/j.patrec.2020.04.005</span></li>
<li><span id="RANSAC">Fischler, M. A., &amp; Bolles, R. C. (1981). Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography. <i>Commun. ACM</i>, <i>24</i>(6), 381–395. https://doi.org/10.1145/358669.358692</span></li></ol>


<span class="post-date">
  Written on
  
  June
  8th,
  2022
  by
  
    Vivien
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Adding Text (Really) inside Pictures and Videos&amp;url=https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html&amp;title=Adding Text (Really) inside Pictures and Videos" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
    <a href="https://plus.google.com/share?url=https://vivien000.github.io/blog/journal/adding-text-inside-pictures-and-videos.html" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
  </div>
</div>



  <section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = "unsupervisedthoughts";
    var disqus_identifier = "/journal/adding-text-inside-pictures-and-videos.html";
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/vivien000" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/vivien000000" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://vivien000.github.io/blog/rss-feed.xml" target="_blank"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:vivien@melix.net" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="https://vivien000.github.io/blog/menu/about.html">Unsupervised Thoughts | A blog on machine learning by Vivien</a></div>
</footer>


  </div>

</body>
</html>
